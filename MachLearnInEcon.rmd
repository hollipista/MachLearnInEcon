---
title: "Machine Learning in Econometrics - Group Work"
author: "Hollosi, Pokasz, Soos, Szabo"
date: "2023-12-12"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(zoo)
library(Hmisc)

#library(tree) 
library(rpart)
#library(ISLR2)
library(caret)
```

## About dataset

A novel dataset for bankruptcy prediction related to American public companies listed on the New York Stock Exchange and NASDAQ is provided. The dataset comprises accounting data from 8,262 distinct companies recorded during the period spanning from 1999 to 2018.

For further information: [kaggle.com](https://www.kaggle.com/datasets/utkarshx27/american-companies-bankruptcy-prediction-dataset/)

Status_label column contains the flag whether the company has gone to bankrupt after the last reported year.
It's permanently 'failed' for seased companies not just for the last period!

```{r data intake}

download.file(url = "https://raw.githubusercontent.com/hollipista/MachLearnInEcon/main/american_bankruptcy.zip", 
              destfile = "american_bankruptcy.zip", mode = "wb")
unzip("american_bankruptcy.zip")

df <- read_csv("american_bankruptcy.csv") %>% 
  arrange(company_name, year) %>% 
  group_by(company_name) %>%
  mutate(last = ifelse(row_number() == max(row_number()), 1, 0)) %>% #find last reported year for each company
  ungroup() 

colnames <- c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", 
              "X10", "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18") 

for (col in colnames) { #moving avg for each variable
  new_col_name <- paste0(col, "_rollmean")
  df <- df %>%
    group_by(company_name) %>%
    mutate(!!new_col_name := rollmean(!!sym(col), k = 3, align = "right", fill = NA)) %>%
    ungroup()
}

df <- df %>%  #flag the last year of bankrupted companies = year before bankrupcy
  mutate(bankrupt = ifelse(last == 1 & status_label == 'failed', 1, 0))

table(df$bankrupt) # number of bankrupcies

for (col in colnames) { #change variables
  new_col_name <- paste0(col, "_chg")
  roll_col_name <- paste0(col, "_rollmean")
  df <- df %>%
    group_by(company_name) %>%
    mutate(!!new_col_name := (!!sym(roll_col_name)-lag(!!sym(roll_col_name), n=1))/abs(lag(!!sym(roll_col_name), n=1))) %>%
    ungroup()
}

df <- df %>% # I keep years that has 4 year lead: 3 for the moving average + 1 for the change
  drop_na()

table(df$bankrupt) # number of bankrupcies

colnameschg <- c("X1_chg", "X2_chg", "X3_chg", "X4_chg", "X5_chg", "X6_chg", "X7_chg", "X8_chg", "X9_chg", 
              "X10_chg", "X11_chg", "X12_chg", "X13_chg", "X14_chg", "X15_chg", "X16_chg", "X17_chg", "X18_chg") 
describe(df)

# There are a couple of extreme high values especially in case of X5 and X11:
# inventory and long-term debt. As both variables could be zero and the division
# by zero could result infinite floating. 

df %>% 
  summarise(across(where(is.numeric), ~ quantile(., probs = 0.995, na.rm = TRUE))) %>% 
  t()

# I'm winsorizing the extreme increases at +300%
df <- df %>%
  mutate(across(all_of(colnameschg), ~ pmin(3, .)))

df <- df %>% 
  select(all_of(c(colnameschg, "bankrupt")))
  
```

## Prepared dataset

1. I've calculated 3-month moving average for all variables
2. Get the yearly change for all: (t2-t1)/t1
3. Winsorized the extreme values (because some statments could be zero)
4. Dropped unnecessary variables

Final structure: 
bankrupt dummy: 0=no, 1=yes (at the last year before bankrupcy)
X1_chg to X18_chg: yearly change in item of financial statments (used 3-years moving average)

```{r regression tree}
# we fit a regression tree
set.seed(1923)
train <- sample(1:nrow(df), nrow(df) * 0.7)
train_data <- df[train, ]
test_data <- df[-train, ]

# Due to the very few positive tag (=bankrupts) I've used an overweigt for the bankrupt=1 cases
weights <- ifelse(train_data$bankrupt == 1, 10, 1) 

tree_model <- rpart(bankrupt ~ ., data = train_data, weights = weights, method = "class")
tree_model

# show tree structure
plot(tree_model)
text(tree_model)

# use the rpart.control function to see whether pruning the tree will improve performance.
cv_model <- rpart(bankrupt ~ ., data = train_data, weights = weights, method = "class",
                    control = rpart.control(cp = 0.01, minsplit = 10, xval = 10))
plotcp(cv_model)

# prune the tree
pruned_model <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"])
plot(pruned_model)
text(pruned_model)

# prediction
predictions <- predict(pruned_model, newdata = test_data, type = "class")
actual_values <- as.factor(test_data$bankrupt)
confusion_matrix <- confusionMatrix(predictions, actual_values)
print(confusion_matrix)

```

```{r random forrest}


```

