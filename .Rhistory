knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
install.packages('tidyverse')
library(zoo)
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(zoo)
library(Hmisc)
#library(tree)
library(rpart)
#library(ISLR2)
library(caret)
install.packages("recipes")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(zoo)
library(Hmisc)
#library(tree)
library(rpart)
#library(ISLR2)
library(caret)
download.file(url = "https://raw.githubusercontent.com/hollipista/MachLearnInEcon/main/american_bankruptcy.zip",
destfile = "american_bankruptcy.zip", mode = "wb")
unzip("american_bankruptcy.zip")
unzip("american_bankruptcy.zip")
df <- read_csv("american_bankruptcy.csv") %>%
arrange(company_name, year) %>%
group_by(company_name) %>%
mutate(last = ifelse(row_number() == max(row_number()), 1, 0)) %>% #find last reported year for each company
ungroup()
download.file(url = "https://raw.githubusercontent.com/hollipista/MachLearnInEcon/main/american_bankruptcy.zip",
destfile = "american_bankruptcy.zip", mode = "wb")
unzip("american_bankruptcy.zip")
wd()
getwd()
ls
list.files(getwd())
df <- read_csv("american_bankruptcy.csv") %>%
arrange(company_name, year) %>%
group_by(company_name) %>%
mutate(last = ifelse(row_number() == max(row_number()), 1, 0)) %>% #find last reported year for each company
ungroup()
colnames <- c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9",
"X10", "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18")
for (col in colnames) { #moving avg for each variable
new_col_name <- paste0(col, "_rollmean")
df <- df %>%
group_by(company_name) %>%
mutate(!!new_col_name := rollmean(!!sym(col), k = 3, align = "right", fill = NA)) %>%
ungroup()
}
df <- df %>%  #flag the last year of bankrupted companies = year before bankrupcy
mutate(bankrupt = ifelse(last == 1 & status_label == 'failed', 1, 0))
table(df$bankrupt) # number of bankrupcies
for (col in colnames) { #change variables
new_col_name <- paste0(col, "_chg")
roll_col_name <- paste0(col, "_rollmean")
df <- df %>%
group_by(company_name) %>%
mutate(!!new_col_name := (!!sym(roll_col_name)-lag(!!sym(roll_col_name), n=1))/abs(lag(!!sym(roll_col_name), n=1))) %>%
ungroup()
}
df <- df %>% # I keep years that has 4 year lead: 3 for the moving average + 1 for the change
drop_na()
table(df$bankrupt) # number of bankrupcies
colnameschg <- c("X1_chg", "X2_chg", "X3_chg", "X4_chg", "X5_chg", "X6_chg", "X7_chg", "X8_chg", "X9_chg",
"X10_chg", "X11_chg", "X12_chg", "X13_chg", "X14_chg", "X15_chg", "X16_chg", "X17_chg", "X18_chg")
describe(df)
# There are a couple of extreme high values especially in case of X5 and X11:
# inventory and long-term debt. As both variables could be zero and the division
# by zero could result infinite floating.
df %>%
summarise(across(where(is.numeric), ~ quantile(., probs = 0.995, na.rm = TRUE))) %>%
t()
# I'm winsorizing the extreme increases at +300%
df <- df %>%
mutate(across(all_of(colnameschg), ~ pmin(3, .)))
df <- df %>%
select(all_of(c(colnameschg, "bankrupt")))
# we fit a regression tree
set.seed(1923)
train <- sample(1:nrow(df), nrow(df) * 0.7)
train_data <- df[train, ]
test_data <- df[-train, ]
weights <- ifelse(train_data$bankrupt == 1, 10, 1)
tree_model <- rpart(bankrupt ~ ., data = train_data, weights = weights, method = "class")
tree_model
plot(tree_model)
text(tree_model)
cv_model <- rpart(bankrupt ~ ., data = train_data, weights = weights, method = "class",
control = rpart.control(cp = 0.01, minsplit = 10, xval = 10))
plotcp(cv_model)
# prune the tree
pruned_model <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"])
plot(pruned_model)
text(pruned_model)
predictions <- predict(pruned_model, newdata = test_data, type = "class")
actual_values <- test_data$bankrupt
confusion_matrix <- confusionMatrix(predictions, actual_values)
predictions
actual_values
confusionMatrix(predictions, actual_values)
class(predictions)
class(actual_values)
actual_values <- as.factor(test_data$bankrupt)
actual_values <- as.factor(test_data$bankrupt)
class(actual_values)
actual_values
confusion_matrix <- confusionMatrix(predictions, actual_values)
print(confusion_matrix)
library(tree) # The tree library is used to construct classification and regression trees
library(ISLR2)
##################### Regression Trees ####################
# we fit a regression tree to the Boston data set
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston) / 2) # training sample
tree.boston <- tree(medv ~ ., Boston , subset = train) # fit the tree to the training sample
summary(tree.boston)
# show tree structure
plot(tree.boston)
text(tree.boston , pretty = 0)
# use the cv.tree() function to see whether pruning the tree will improve performance.
cv.boston <- cv.tree(tree.boston) # Runs a K-fold cross-validation experiment
plot(cv.boston$size , cv.boston$dev, type = "b")
# prune the tree
prune.boston <- prune.tree(tree.boston , best = 5)
plot(prune.boston)
text(prune.boston , pretty = 0)
# In keeping with the cross-validation results, we use the unpruned tree to make predictions on the test set.
yhat <- predict(tree.boston , newdata = Boston[-train , ])
boston.test <- Boston[-train, "medv"]
plot(yhat , boston.test)
abline(0, 1)
mean((yhat - boston.test)^2)
